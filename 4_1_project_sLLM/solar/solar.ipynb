{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1,2' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AdamW, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model,PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\" \n",
    "#torch.backends.cuda.matmul.allow_tf32=True\n",
    "#torch.set_float32_matmul_precision('medium')\n",
    "#torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "model_id = \"LDCC/LDCC-SOLAR-10.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,  eos_token='</s>')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # 패딩을 문장 뒤에 추가\n",
    "max_length = 1024\n",
    "dataset = load_dataset(\"jojo0217/korean_safe_conversation\",split=\"train\")\n",
    "\n",
    "\n",
    "formatted_data = []\n",
    "for row in dataset:\n",
    "    input_text = f'''### User:\\n{row['instruction']}\\n\\n### Assistant:\\n{row['output']}'''\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_length)\n",
    "    formatted_data.append(input_ids)\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data = torch.cat(formatted_data, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38650d1171664497a503dea50ea38d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 31457280 || all params: 5645930496 || trainable%: 0.5571673264891711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26980' max='26980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26980/26980 29:21:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.693600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.705700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.693800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.698100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.684400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.682900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.672100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.661300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.363500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.376200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.382300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.387700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.377400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=26980, training_loss=1.5341458172865317, metrics={'train_runtime': 105690.4626, 'train_samples_per_second': 0.511, 'train_steps_per_second': 0.255, 'total_flos': 3.5441356411911537e+18, 'train_loss': 1.5341458172865317, 'epoch': 2.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드\n",
    "\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    #target_modules=[\"query_key_value\"], \n",
    "    target_modules=[\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\"],\n",
    "    lora_dropout=0.05, \n",
    "    bias=\"none\", \n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=formatted_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        num_train_epochs=2,\n",
    "        per_device_train_batch_size=8,\n",
    "        gradient_accumulation_steps=1,\n",
    "      #  max_steps=50,\n",
    "        learning_rate=1e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1000,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_8bit\"\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolar-ft\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(new_model)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "new_model = \"solar-ft\"\n",
    "trainer.model.save_pretrained(new_model)\n",
    "# trainer.tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989c2668e0a04c58872a30748fa4acbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             device_map=\"auto\",\n",
    "                                             #torch_dtype=torch.float32,\n",
    "                                             )\n",
    "#model = PeftModel.from_pretrained(model, new_model,device_map=\"auto\")\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []\n",
    "qs = []\n",
    "gts = []\n",
    "for row in dataset:\n",
    "    input_text = f'''### User:\\n{row['instruction']}\\n\\n### Assistant:\\n'''\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt', padding='max_length', truncation=True, max_length=max_length)\n",
    "    formatted_data.append(input_ids)\n",
    "    qs.append(row['instruction'])\n",
    "    gts.append(row['output'])\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/26979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/decs_jupyter_lab/venvs311/llama2venv/lib/python3.11/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/26979\n",
      "2/26979\n",
      "3/26979\n",
      "4/26979\n",
      "5/26979\n",
      "6/26979\n",
      "7/26979\n",
      "8/26979\n",
      "9/26979\n",
      "10/26979\n",
      "11/26979\n",
      "12/26979\n",
      "13/26979\n",
      "14/26979\n",
      "15/26979\n",
      "16/26979\n",
      "17/26979\n",
      "18/26979\n",
      "19/26979\n",
      "20/26979\n",
      "21/26979\n",
      "22/26979\n",
      "23/26979\n",
      "24/26979\n",
      "25/26979\n",
      "26/26979\n",
      "27/26979\n",
      "28/26979\n",
      "29/26979\n",
      "30/26979\n",
      "31/26979\n",
      "32/26979\n",
      "33/26979\n",
      "34/26979\n",
      "35/26979\n",
      "36/26979\n",
      "37/26979\n",
      "38/26979\n",
      "39/26979\n",
      "40/26979\n",
      "41/26979\n",
      "42/26979\n",
      "43/26979\n",
      "44/26979\n",
      "45/26979\n",
      "46/26979\n",
      "47/26979\n",
      "48/26979\n",
      "49/26979\n",
      "50/26979\n",
      "51/26979\n",
      "52/26979\n",
      "53/26979\n",
      "54/26979\n",
      "55/26979\n",
      "56/26979\n",
      "57/26979\n",
      "58/26979\n",
      "59/26979\n",
      "60/26979\n",
      "61/26979\n",
      "62/26979\n",
      "63/26979\n",
      "64/26979\n",
      "65/26979\n",
      "66/26979\n",
      "67/26979\n",
      "68/26979\n",
      "69/26979\n",
      "70/26979\n",
      "71/26979\n",
      "72/26979\n",
      "73/26979\n",
      "74/26979\n",
      "75/26979\n",
      "76/26979\n",
      "77/26979\n",
      "78/26979\n",
      "79/26979\n",
      "80/26979\n",
      "81/26979\n",
      "82/26979\n",
      "83/26979\n",
      "84/26979\n",
      "85/26979\n",
      "86/26979\n",
      "87/26979\n",
      "88/26979\n",
      "89/26979\n",
      "90/26979\n",
      "91/26979\n",
      "92/26979\n",
      "93/26979\n",
      "94/26979\n",
      "95/26979\n",
      "96/26979\n",
      "97/26979\n",
      "98/26979\n",
      "99/26979\n",
      "100/26979\n",
      "101/26979\n",
      "102/26979\n",
      "103/26979\n",
      "104/26979\n",
      "105/26979\n",
      "106/26979\n",
      "107/26979\n",
      "108/26979\n",
      "109/26979\n",
      "110/26979\n",
      "111/26979\n",
      "112/26979\n",
      "113/26979\n",
      "114/26979\n",
      "115/26979\n",
      "116/26979\n",
      "117/26979\n",
      "118/26979\n",
      "119/26979\n",
      "120/26979\n",
      "121/26979\n",
      "122/26979\n",
      "123/26979\n",
      "124/26979\n",
      "125/26979\n",
      "126/26979\n",
      "127/26979\n",
      "128/26979\n",
      "129/26979\n",
      "130/26979\n",
      "131/26979\n",
      "132/26979\n",
      "133/26979\n",
      "134/26979\n",
      "135/26979\n",
      "136/26979\n",
      "137/26979\n",
      "138/26979\n",
      "139/26979\n",
      "140/26979\n",
      "141/26979\n",
      "142/26979\n",
      "143/26979\n",
      "144/26979\n",
      "145/26979\n",
      "146/26979\n",
      "147/26979\n",
      "148/26979\n",
      "149/26979\n",
      "150/26979\n",
      "151/26979\n",
      "152/26979\n",
      "153/26979\n",
      "154/26979\n",
      "155/26979\n",
      "156/26979\n",
      "157/26979\n",
      "158/26979\n",
      "159/26979\n",
      "160/26979\n",
      "161/26979\n",
      "162/26979\n",
      "163/26979\n",
      "164/26979\n",
      "165/26979\n",
      "166/26979\n",
      "167/26979\n",
      "168/26979\n",
      "169/26979\n",
      "170/26979\n",
      "171/26979\n",
      "172/26979\n",
      "173/26979\n",
      "174/26979\n",
      "175/26979\n",
      "176/26979\n",
      "177/26979\n",
      "178/26979\n",
      "179/26979\n",
      "180/26979\n",
      "181/26979\n",
      "182/26979\n",
      "183/26979\n",
      "184/26979\n",
      "185/26979\n",
      "186/26979\n",
      "187/26979\n",
      "188/26979\n",
      "189/26979\n",
      "190/26979\n",
      "191/26979\n",
      "192/26979\n",
      "193/26979\n",
      "194/26979\n",
      "195/26979\n",
      "196/26979\n",
      "197/26979\n",
      "198/26979\n",
      "199/26979\n",
      "200/26979\n",
      "201/26979\n",
      "202/26979\n",
      "203/26979\n",
      "204/26979\n",
      "205/26979\n",
      "206/26979\n",
      "207/26979\n",
      "208/26979\n",
      "209/26979\n",
      "210/26979\n",
      "211/26979\n",
      "212/26979\n",
      "213/26979\n",
      "214/26979\n",
      "215/26979\n",
      "216/26979\n",
      "217/26979\n",
      "218/26979\n",
      "219/26979\n",
      "220/26979\n",
      "221/26979\n",
      "222/26979\n",
      "223/26979\n",
      "224/26979\n",
      "225/26979\n",
      "226/26979\n",
      "227/26979\n",
      "228/26979\n",
      "229/26979\n",
      "230/26979\n",
      "231/26979\n",
      "232/26979\n",
      "233/26979\n",
      "234/26979\n",
      "235/26979\n",
      "236/26979\n",
      "237/26979\n",
      "238/26979\n",
      "239/26979\n",
      "240/26979\n",
      "241/26979\n",
      "242/26979\n",
      "243/26979\n",
      "244/26979\n",
      "245/26979\n",
      "246/26979\n",
      "247/26979\n",
      "248/26979\n",
      "249/26979\n",
      "250/26979\n",
      "251/26979\n",
      "252/26979\n",
      "253/26979\n",
      "254/26979\n",
      "255/26979\n",
      "256/26979\n",
      "257/26979\n",
      "258/26979\n",
      "259/26979\n",
      "260/26979\n",
      "261/26979\n",
      "262/26979\n",
      "263/26979\n",
      "264/26979\n",
      "265/26979\n",
      "266/26979\n",
      "267/26979\n",
      "268/26979\n",
      "269/26979\n",
      "270/26979\n",
      "271/26979\n",
      "272/26979\n",
      "273/26979\n",
      "274/26979\n",
      "275/26979\n",
      "276/26979\n",
      "277/26979\n",
      "278/26979\n",
      "279/26979\n",
      "280/26979\n",
      "281/26979\n",
      "282/26979\n",
      "283/26979\n",
      "284/26979\n",
      "285/26979\n",
      "286/26979\n",
      "287/26979\n",
      "288/26979\n",
      "289/26979\n",
      "290/26979\n",
      "291/26979\n",
      "292/26979\n",
      "293/26979\n",
      "294/26979\n",
      "295/26979\n",
      "296/26979\n",
      "297/26979\n",
      "298/26979\n",
      "299/26979\n",
      "300/26979\n",
      "301/26979\n",
      "302/26979\n",
      "303/26979\n",
      "304/26979\n",
      "305/26979\n",
      "306/26979\n",
      "307/26979\n",
      "308/26979\n",
      "309/26979\n",
      "310/26979\n",
      "311/26979\n",
      "312/26979\n",
      "313/26979\n",
      "314/26979\n",
      "315/26979\n",
      "316/26979\n",
      "317/26979\n",
      "318/26979\n",
      "319/26979\n",
      "320/26979\n",
      "321/26979\n",
      "322/26979\n",
      "323/26979\n",
      "324/26979\n",
      "325/26979\n",
      "326/26979\n",
      "327/26979\n",
      "328/26979\n",
      "329/26979\n",
      "330/26979\n",
      "331/26979\n",
      "332/26979\n",
      "333/26979\n",
      "334/26979\n",
      "335/26979\n",
      "336/26979\n",
      "337/26979\n",
      "338/26979\n",
      "339/26979\n",
      "340/26979\n",
      "341/26979\n",
      "342/26979\n",
      "343/26979\n",
      "344/26979\n",
      "345/26979\n",
      "346/26979\n",
      "347/26979\n",
      "348/26979\n",
      "349/26979\n",
      "350/26979\n",
      "351/26979\n",
      "352/26979\n",
      "353/26979\n",
      "354/26979\n",
      "355/26979\n",
      "356/26979\n",
      "357/26979\n",
      "358/26979\n",
      "359/26979\n",
      "360/26979\n",
      "361/26979\n",
      "362/26979\n",
      "363/26979\n",
      "364/26979\n",
      "365/26979\n",
      "366/26979\n",
      "367/26979\n",
      "368/26979\n",
      "369/26979\n",
      "370/26979\n",
      "371/26979\n",
      "372/26979\n",
      "373/26979\n",
      "374/26979\n",
      "375/26979\n",
      "376/26979\n",
      "377/26979\n",
      "378/26979\n",
      "379/26979\n",
      "380/26979\n",
      "381/26979\n",
      "382/26979\n",
      "383/26979\n",
      "384/26979\n",
      "385/26979\n",
      "386/26979\n",
      "387/26979\n",
      "388/26979\n",
      "389/26979\n",
      "390/26979\n",
      "391/26979\n",
      "392/26979\n",
      "393/26979\n",
      "394/26979\n",
      "395/26979\n",
      "396/26979\n",
      "397/26979\n",
      "398/26979\n",
      "399/26979\n",
      "400/26979\n",
      "401/26979\n",
      "402/26979\n",
      "403/26979\n",
      "404/26979\n",
      "405/26979\n",
      "406/26979\n",
      "407/26979\n",
      "408/26979\n",
      "409/26979\n",
      "410/26979\n",
      "411/26979\n",
      "412/26979\n",
      "413/26979\n",
      "414/26979\n",
      "415/26979\n",
      "416/26979\n",
      "417/26979\n",
      "418/26979\n",
      "419/26979\n",
      "420/26979\n",
      "421/26979\n",
      "422/26979\n",
      "423/26979\n",
      "424/26979\n",
      "425/26979\n",
      "426/26979\n",
      "427/26979\n",
      "428/26979\n",
      "429/26979\n",
      "430/26979\n",
      "431/26979\n",
      "432/26979\n",
      "433/26979\n",
      "434/26979\n",
      "435/26979\n",
      "436/26979\n",
      "437/26979\n",
      "438/26979\n",
      "439/26979\n",
      "440/26979\n",
      "441/26979\n",
      "442/26979\n",
      "443/26979\n",
      "444/26979\n",
      "445/26979\n",
      "446/26979\n",
      "447/26979\n",
      "448/26979\n",
      "449/26979\n",
      "450/26979\n",
      "451/26979\n",
      "452/26979\n",
      "453/26979\n",
      "454/26979\n",
      "455/26979\n",
      "456/26979\n",
      "457/26979\n",
      "458/26979\n",
      "459/26979\n",
      "460/26979\n",
      "461/26979\n",
      "462/26979\n",
      "463/26979\n",
      "464/26979\n",
      "465/26979\n",
      "466/26979\n",
      "467/26979\n",
      "468/26979\n",
      "469/26979\n",
      "470/26979\n",
      "471/26979\n",
      "472/26979\n",
      "473/26979\n",
      "474/26979\n",
      "475/26979\n",
      "476/26979\n",
      "477/26979\n",
      "478/26979\n",
      "479/26979\n",
      "480/26979\n",
      "481/26979\n",
      "482/26979\n",
      "483/26979\n",
      "484/26979\n",
      "485/26979\n",
      "486/26979\n",
      "487/26979\n",
      "488/26979\n",
      "489/26979\n",
      "490/26979\n",
      "491/26979\n",
      "492/26979\n",
      "493/26979\n",
      "494/26979\n",
      "495/26979\n",
      "496/26979\n",
      "497/26979\n",
      "498/26979\n",
      "499/26979\n",
      "500/26979\n",
      "501/26979\n",
      "502/26979\n",
      "503/26979\n",
      "504/26979\n",
      "505/26979\n",
      "506/26979\n",
      "507/26979\n",
      "508/26979\n",
      "509/26979\n",
      "510/26979\n",
      "511/26979\n",
      "512/26979\n",
      "513/26979\n",
      "514/26979\n",
      "515/26979\n",
      "516/26979\n",
      "517/26979\n",
      "518/26979\n",
      "519/26979\n",
      "520/26979\n",
      "521/26979\n",
      "522/26979\n",
      "523/26979\n"
     ]
    }
   ],
   "source": [
    "with open('bigdata/out.txt', 'w', encoding='utf-8') as file:\n",
    "    pass\n",
    "\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    #tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "for idx in range(len(formatted_data)):\n",
    "    \n",
    "    print(f\"{idx}/{len(formatted_data)}\")\n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = model.generate(\n",
    "            formatted_data[idx],\n",
    "            max_new_tokens=512,\n",
    "            eos_token_id=terminators,\n",
    "        #     do_sample=True,\n",
    "        #     temperature=1,\n",
    "        #     top_p=0.9,\n",
    "        )\n",
    "        full_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "        answer_start = full_text.find(\"\\n\\n### Assistant:\") + len(\"\\n\\n### Assistant:\")\n",
    "        answer_only = full_text[answer_start:].strip()\n",
    "        dic = {\"question\":qs[idx],\"answer\":answer_only,\"goldanswer\":gts[idx]}\n",
    "        dic_str = '\\n'.join([f\"{key}: {value}\" for key, value in dic.items()])\n",
    "        with open('bigdata/out.txt', 'a', encoding='utf-8') as file:\n",
    "            file.write(dic_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311llama2",
   "language": "python",
   "name": "py311llama2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
