{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4' # nvidia-smi로 비어있는 gpu 확인하고 여기서 선택할것!\n",
    "\n",
    "\n",
    "#from huggingface_hub import notebook_login\n",
    "\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "import pandas as pd\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 예시\n",
    "preds = [\n",
    "    \"이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\",\n",
    "    \"데이콘은 플랫폼입니다.\"\n",
    "]\n",
    "\n",
    "gts = [\n",
    "    \"이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\",\n",
    "    \"데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플에 대한 Cosine Similarity 산식\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 :  이번 경진대회는 질의 응답 처리를 수행하는 AI 모델을 개발해야합니다.\n",
      "정답 :  이번 경진대회의 주제는 도배 하자 질의 응답 AI 모델 개발입니다.\n",
      "Cosine Similarity Score :  0.83436465\n",
      "--------------------\n",
      "예측 :  데이콘은 플랫폼입니다.\n",
      "정답 :  데이콘은 국내 최대의 AI 경진대회 플랫폼입니다.\n",
      "Cosine Similarity Score :  0.6281873\n",
      "--------------------\n",
      "전체 샘플의 Cosine Similarity Score 평균 :  0.731276\n"
     ]
    }
   ],
   "source": [
    "sample_scores = []\n",
    "for pred, gt in zip(preds, gts):\n",
    "    # 생성된 답변 내용을 512 Embedding Vector로 변환\n",
    "    pred_embed = model.encode(pred)\n",
    "    gt_embed = model.encode(gt)\n",
    "    \n",
    "    sample_score = cosine_similarity(gt_embed, pred_embed)\n",
    "    # Cosine Similarity Score가 0보다 작으면 0으로 간주\n",
    "    sample_score = max(sample_score, 0)\n",
    "    print('예측 : ', pred)\n",
    "    print('정답 : ', gt)\n",
    "    print('Cosine Similarity Score : ', sample_score)\n",
    "    print('-'*20)\n",
    "    sample_scores.append(sample_score)\n",
    "print('전체 샘플의 Cosine Similarity Score 평균 : ', np.mean(sample_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./bigdata/train.csv\")\n",
    "input_dict = {\"utterance\":[]}\n",
    "for _, row in data.iterrows():\n",
    "    for q_col in ['질문_1', '질문_2']:\n",
    "        for a_col in ['답변_1', '답변_2', '답변_3', '답변_4', '답변_5']:\n",
    "            input_list.append({\"question\":row[q_col],\"answer\":row[a_col]})\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(path):\n",
    "    test_question = []\n",
    "    test = pd.read_csv(path)\n",
    "    for ut in test['질문']:\n",
    "        test_question.append(ut)\n",
    "\n",
    "    return test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q= read_input('./bigdata/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_q_embed = []\n",
    "\n",
    "for gt_q_dic in input_list:\n",
    "    gt_q_embed.append({\"question_embed\":model.encode(gt_q_dic[\"question\"]),\"question\":gt_q_dic[\"question\"],\"answer\":gt_q_dic[\"answer\"]})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def translate(text):\n",
    "    max_sim_dic = {\"question_embed\":None,\"question\":None,\"answer\":None}\n",
    "    max_sim = -100\n",
    "    text_embed = model.encode(text)\n",
    "    for gt_dic in gt_q_embed:\n",
    "        tmp_sim = cosine_similarity(gt_dic[\"question_embed\"], text_embed)\n",
    "        if tmp_sim > max_sim:\n",
    "            if \"장점\" or \"단점\" in text:\n",
    "                if (\"장점\" in text and \"단점\" in gt_dic[\"question\"]) or (\"단점\" in text and \"장점\" in gt_dic[\"question\"]):\n",
    "                    print(\"there was an error\")\n",
    "                    continue\n",
    "            max_sim = tmp_sim\n",
    "            max_sim_dic = {\"question_embed\":gt,\"question\":gt_dic[\"question\"],\"answer\":gt_dic[\"answer\"]}\n",
    "       \n",
    "    \n",
    "    return max_sim_dic[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_framework(text):\n",
    "    pred = \"\"\n",
    "    dividers = [\"또한,\",\"그리고\"]\n",
    "    for divider in dividers:\n",
    "        \n",
    "        if divider in text:\n",
    "            text1 = text.split(divider)[0].strip()\n",
    "            text2 = text.split(divider)[1].strip()\n",
    "            pred = translate(text1) +\" \"+divider+\" \"+ translate(text2)\n",
    "            return pred\n",
    "    else:\n",
    "        pred = translate(text)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_text :  방청 페인트의 종류에는 어떤 것들이 있는지 알고 계신가요? 또한, 원목사이딩을 사용하는 것에 어떤 단점이 있을까요?\n",
      "result :       방청페인트의 종류는 광명단페인트, 방청산화철페인트, 알미늄페인트, 역청질페인트, 워시프라이머, 크롬산아연페인트, 규산염페인트가 있습니다. 또한, 원목사이딩의 단점은 가격대가 높고 관리가 어려우며 습기에 약해 뒤틀림, 부서짐, 수축/팽장이 생길 수 있다는 점입니다.\n",
      "\n",
      "\n",
      "source_text :  도배지에 녹은 자국이 발생하는 주된 원인과 그 해결 방법은 무엇인가요?\n",
      "result :       해당 현상은 녹 오염으로 도배지에 붉은색의 녹이 베어나오는 현상입니다. 도배지에 녹오염이 발생하는 원인 - 책임소재 - 해결방법에 대해 설명드리겠습니다. 1. 공간 내 높은 습도 원인 : 높은 습기로 인해 도배지 안쪽의 금속의 녹이 도배지에 베어나올 수 있습니다. 책임소재 : 건물의 소유자나 거주자가 습기 관리의 책임이 있습니다. 해결 방법 : 제습기 가동, 환기를 통해 실내 적정 습도를 유지하고 전문가의 도움을 받아 보수작업하는 것을 추천합니다. 2. 누수 원인 : 누수에 의해 도배지가 젖어 있는 상태가 지속되면 곰팡이가 발생할 수 있습니다. 책임소재 : 건물의 소유자나 거주자가 책임이 있습니다. 해결 방법 : 보수작업을 통해 누수를 제거하고 곰팡이가 발생한 도배지의 부분 및 전체를 교체해야 합니다. 해당 작업은 개인이 하기 어려운 작업이니 전문가의 도움을 받는 것을 추천합니다.\n",
      "\n",
      "\n",
      "source_text :  큐블럭의 단점을 알려주세요. 또한, 압출법 단열판을 사용하는 것의 장점은 무엇인가요?\n",
      "result :       큐블럭은 일반 벽돌에 비해 가격이 비싸고 균열이 생기기 쉬우며 습기로 인해 하자가 발생할 수 있다는 점이 단점입니다. 또한, 압출법단열판은 시간이 지나면 단열 성능이 떨어지는 경시현상이 있고 비드법 단열재에 비래 가격이 높은 편이며 충격에 약해서 파손율이 높은 편이라는 단점이 있습니다.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(len(test_q)):\n",
    "    sr_text = test_q[i] # dialect\n",
    "    tg_text = translate_framework(sr_text) # translate\n",
    "    preds.append(tg_text)\n",
    "    if i<3:\n",
    "        print(\"source_text : \",sr_text)\n",
    "        print(\"result :      \",tg_text)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터셋의 모든 질의에 대한 답변으로부터 512 차원의 Embedding Vector 추출\n",
    "# 평가를 위한 Embedding Vector 추출에 활용하는 모델은 'distiluse-base-multilingual-cased-v1' 이므로 반드시 확인해주세요.\n",
    "from sentence_transformers import SentenceTransformer # SentenceTransformer Version 2.2.2\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(distiluse-base-multilingual-cased-v1) 불러오기\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "# 생성한 모든 응답(답변)으로부터 Embedding Vector 추출\n",
    "pred_embeddings = model.encode(preds)\n",
    "pred_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vec_0</th>\n",
       "      <th>vec_1</th>\n",
       "      <th>vec_2</th>\n",
       "      <th>vec_3</th>\n",
       "      <th>vec_4</th>\n",
       "      <th>vec_5</th>\n",
       "      <th>vec_6</th>\n",
       "      <th>vec_7</th>\n",
       "      <th>vec_8</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_502</th>\n",
       "      <th>vec_503</th>\n",
       "      <th>vec_504</th>\n",
       "      <th>vec_505</th>\n",
       "      <th>vec_506</th>\n",
       "      <th>vec_507</th>\n",
       "      <th>vec_508</th>\n",
       "      <th>vec_509</th>\n",
       "      <th>vec_510</th>\n",
       "      <th>vec_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>-0.020143</td>\n",
       "      <td>0.015142</td>\n",
       "      <td>0.017840</td>\n",
       "      <td>0.064733</td>\n",
       "      <td>0.019003</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>-0.006164</td>\n",
       "      <td>-0.006306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013746</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.032005</td>\n",
       "      <td>-0.039729</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.030455</td>\n",
       "      <td>0.039992</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.013259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>-0.023421</td>\n",
       "      <td>-0.041167</td>\n",
       "      <td>0.039610</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>-0.017209</td>\n",
       "      <td>0.012354</td>\n",
       "      <td>-0.010817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>-0.014981</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>-0.051459</td>\n",
       "      <td>-0.043125</td>\n",
       "      <td>0.052939</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>-0.038103</td>\n",
       "      <td>0.043188</td>\n",
       "      <td>-0.012774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>-0.044065</td>\n",
       "      <td>-0.055140</td>\n",
       "      <td>-0.020158</td>\n",
       "      <td>0.126544</td>\n",
       "      <td>-0.075034</td>\n",
       "      <td>-0.013657</td>\n",
       "      <td>-0.011753</td>\n",
       "      <td>0.030937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041547</td>\n",
       "      <td>-0.020535</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>-0.022430</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>-0.043727</td>\n",
       "      <td>-0.031565</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.107110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>0.010828</td>\n",
       "      <td>0.039439</td>\n",
       "      <td>-0.025302</td>\n",
       "      <td>-0.085114</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>-0.075234</td>\n",
       "      <td>-0.015612</td>\n",
       "      <td>0.027546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>0.056598</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>-0.032400</td>\n",
       "      <td>0.030189</td>\n",
       "      <td>-0.047903</td>\n",
       "      <td>0.015931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>-0.043673</td>\n",
       "      <td>-0.049715</td>\n",
       "      <td>-0.022141</td>\n",
       "      <td>-0.005375</td>\n",
       "      <td>-0.022107</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>0.077968</td>\n",
       "      <td>0.026049</td>\n",
       "      <td>-0.039286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046560</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>-0.010394</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>-0.024329</td>\n",
       "      <td>0.044780</td>\n",
       "      <td>-0.043111</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.066883</td>\n",
       "      <td>-0.051414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     vec_0     vec_1     vec_2     vec_3     vec_4     vec_5  \\\n",
       "0  TEST_000  0.026534 -0.020143  0.015142  0.017840  0.064733  0.019003   \n",
       "1  TEST_001 -0.023421 -0.041167  0.039610  0.005828  0.052292  0.001335   \n",
       "2  TEST_002  0.009344 -0.044065 -0.055140 -0.020158  0.126544 -0.075034   \n",
       "3  TEST_003  0.012937  0.010828  0.039439 -0.025302 -0.085114  0.036850   \n",
       "4  TEST_004 -0.043673 -0.049715 -0.022141 -0.005375 -0.022107 -0.002669   \n",
       "\n",
       "      vec_6     vec_7     vec_8  ...   vec_502   vec_503   vec_504   vec_505  \\\n",
       "0  0.002009 -0.006164 -0.006306  ... -0.013746 -0.000601 -0.032005 -0.039729   \n",
       "1 -0.017209  0.012354 -0.010817  ...  0.012853 -0.014981  0.007259 -0.051459   \n",
       "2 -0.013657 -0.011753  0.030937  ... -0.041547 -0.020535  0.037554 -0.022430   \n",
       "3 -0.075234 -0.015612  0.027546  ...  0.002707  0.037181  0.056598  0.005570   \n",
       "4  0.077968  0.026049 -0.039286  ... -0.046560  0.019589 -0.010394  0.026634   \n",
       "\n",
       "    vec_506   vec_507   vec_508   vec_509   vec_510   vec_511  \n",
       "0  0.001504  0.022239  0.030455  0.039992  0.001381  0.013259  \n",
       "1 -0.043125  0.052939  0.016077 -0.038103  0.043188 -0.012774  \n",
       "2  0.007227  0.005301 -0.043727 -0.031565 -0.049027  0.107110  \n",
       "3  0.001142 -0.007538 -0.032400  0.030189 -0.047903  0.015931  \n",
       "4 -0.024329  0.044780 -0.043111  0.015072  0.066883 -0.051414  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./bigdata/sample_submission.csv')\n",
    "# 제출 양식 파일(sample_submission.csv)을 활용하여 Embedding Vector로 변환한 결과를 삽입\n",
    "submit.iloc[:,1:] = pred_embeddings\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리더보드 제출을 위한 csv파일 생성\n",
    "submit.to_csv('./submit/dacon-v0_submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
