{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/gitfiles/venvs/huggvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import json\n",
    "from ast import literal_eval # 걍 eval쓰면 스트링을 배열로 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, DPRQuestionEncoder, DPRContextEncoder\n",
    "from typing import List\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class BiEncoderRetriever:\n",
    "    def __init__(self) -> None:\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\")\n",
    "        self.question_encoder = DPRQuestionEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\").to(self.device)\n",
    "        self.ctxt_encoder = DPRContextEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-ctx-encoder\").to(self.device)\n",
    "\n",
    "    def encode_summaries(self, summaries: List[str]):\n",
    "        input_dict = self.tokenizer(summaries, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.ctxt_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def encode_question(self, question: str):\n",
    "        input_dict = self.tokenizer(question, padding='max_length', max_length=32, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.question_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def retrieve_top_summaries(self, question: str, summaries: List[str], encoded_summaries: np.ndarray = None, topk: int = 5):\n",
    "        encoded_question = self.encode_question(question)\n",
    "        if encoded_summaries is None:\n",
    "            encoded_summaries = self.encode_summaries(summaries)\n",
    "        else:\n",
    "            encoded_summaries = torch.from_numpy(encoded_summaries).to(self.device)\n",
    "\n",
    "        scores = torch.mm(encoded_question, encoded_summaries.T)\n",
    "        # print(encoded_question.shape)\n",
    "        # print(encoded_summaries.T.shape)\n",
    "        if topk >= len(summaries):\n",
    "            return summaries\n",
    "        top_k = torch.topk(scores, topk).indices.squeeze()\n",
    "        \n",
    "        #print(\"all scores : \")\n",
    "        #for i,v in enumerate(scores[0]):\n",
    "            #print(int(v.item()),end=\" \")\n",
    "        #print()\n",
    "        \n",
    "        return [summaries[i] for i in top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = BiEncoderRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n",
      "now 0 dialog\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'persona_list_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3199203/1034880174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mepl_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"utterance\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"3persona\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#newdic = {\"current\" : dialog_list, \"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mnewdic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"persona_list_1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpersona_list_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"persona_list_2\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpersona_list_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"extracted_persona_list\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepl_list\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mfout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'persona_list_1' is not defined"
     ]
    }
   ],
   "source": [
    "with open(\"./bigdata/persona_output.jsonl\",\"w\") as fout:\n",
    "    print(\"start!\")\n",
    "\n",
    "with open(\"./bigdata/extracted_persona_session3_v1.jsonl\", \"r\") as dialogs:\n",
    "    for num,dialog in enumerate(dialogs):\n",
    "#         if num == 50:\n",
    "#             break;\n",
    "#         else:\n",
    "        print(f\"now {num} dialog\")\n",
    "        dic = json.loads(dialog)\n",
    "        dialog_list = dic[\"current\"]\n",
    "        old_persona_list = dic[\"session1_persona\"] + dic[\"session2_persona\"]\n",
    "        new_persona_list_1 = []\n",
    "        new_persona_list_2 = []\n",
    "        for i,v in enumerate(old_persona_list):\n",
    "            if(v.split()[1]==\"1\"):\n",
    "                new_persona_list_1.append(\"Speaker \"+\" \".join(v.split()[2:]))\n",
    "            elif(v.split()[1]==\"2\"):\n",
    "                new_persona_list_2.append(\"Speaker \"+\" \".join(v.split()[2:]))\n",
    "            else:\n",
    "                print(v.split()[1])\n",
    "                new_persona_list_2.append(\"Speaker \"+\" \".join(v.split()[2:]))\n",
    "        \n",
    "        \n",
    "        with open(\"./bigdata/persona_output.jsonl\",\"a\") as fout:\n",
    "            resultlist = []\n",
    "            for i,v in enumerate(dialog_list):\n",
    "                \n",
    "                question = \" \".join(v.split()[2:])\n",
    "                if(v.split()[1]==\"1:\"):\n",
    "                    personalist = new_persona_list_2\n",
    "                elif(v.split()[1]==\"2:\"):\n",
    "                    personalist = new_persona_list_1\n",
    "                else:\n",
    "                    print(v.split()[1])\n",
    "                    personalist = new_persona_list_1\n",
    "                resultlist.append(rt.retrieve_top_summaries(question, personalist, None, topk=3))\n",
    "            epl_list = []\n",
    "            for d,r in zip(dialog_list,resultlist):\n",
    "                epl_list.append({\"utterance\":d, \"3persona\":r})\n",
    "            #newdic = {\"current\" : dialog_list, \"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\n",
    "            newdic = {\"persona_list_1\": new_persona_list_1,\"persona_list_2\": new_persona_list_2, \"extracted_persona_list\":epl_list}\n",
    "            fout.write(json.dumps(newdic, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is Sarah's favorite animal?\",\n",
      " \"Sarah's favorite food is mexican food.\",\n",
      " \"Sarah's mother is very traditional while Sarah prefers to be more free \"\n",
      " 'spirited.']\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Sarah's favorite animal?\"\n",
    "personalist = ['Sarah is 24 years old.', \n",
    "               'Sarah currently lives in Canada.', \n",
    "               \"Sarah is a swim coach at Sarah's local pool.\", \n",
    "               'Sarah is studying to be a computer programmer.', \n",
    "               'Sarah is also a graduate student.', \n",
    "               'Sarah is now looking for a new job.', \n",
    "               \"Sarah's mother is very traditional while Sarah prefers to be more free spirited.\", \n",
    "               \"Sarah's family and Sarah are from India.\", \n",
    "               \"Sarah's favorite music genre is death metal.\", \n",
    "               'Sarah is a famous twitch streamer.', \n",
    "               'Sarah likes watching war documentaries.', \n",
    "               \"Sarah's favorite food is mexican food.\",\n",
    "               \"What is Sarah's favorite animal?\"\n",
    "              ]\n",
    "pprint(rt.retrieve_top_summaries( # here is using encodings.?!@\n",
    "                question, personalist, None, topk=3\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggvenv",
   "language": "python",
   "name": "huggvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
